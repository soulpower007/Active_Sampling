{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QZxXckQ0wZb"
   },
   "source": [
    "#  Baseline Neural Network Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_eBu_LC90wZg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ar0d1BVW0wZ5"
   },
   "source": [
    "# Next, we can initialize the random number generator to ensure that we always get the same results when executing this code. This will help if we are debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "w5XVf2I50wZ9"
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKt9vHvU0waI"
   },
   "source": [
    "# Load the dataset and split the columns into 60 input variables (X) and 1 output variable (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23867,
     "status": "ok",
     "timestamp": 1528821250472,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "yIru_ape0waM",
    "outputId": "e97ecea3-1f87-4843-be9c-2b5a29acd495"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "df=pd.read_csv(\"https://raw.githubusercontent.com/itsfk/Binary-Classification-Project-1-Sonar-Data/master/sonar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1528821251643,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "enHGsoGD0waX",
    "outputId": "2976adad-3f5c-4f82-e7d6-a732f1edcb24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.2339</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>0.3597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0   0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1   0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2   0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3   0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4   0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "95  0.0181  0.0146  0.0026  0.0141  0.0421  0.0473  0.0361  0.0741  0.1398   \n",
       "96  0.0491  0.0279  0.0592  0.1270  0.1772  0.1908  0.2217  0.0768  0.1246   \n",
       "97  0.1313  0.2339  0.3059  0.4264  0.4010  0.1791  0.1853  0.0055  0.1929   \n",
       "98  0.0201  0.0423  0.0554  0.0783  0.0620  0.0871  0.1201  0.2707  0.1206   \n",
       "99  0.0629  0.1065  0.1526  0.1229  0.1437  0.1190  0.0884  0.0907  0.2107   \n",
       "\n",
       "    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "0   0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "1   0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "2   0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "3   0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "4   0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "..     ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "95  0.1045  ...  0.0223  0.0255  0.0145  0.0233  0.0041  0.0018  0.0048   \n",
       "96  0.2028  ...  0.0081  0.0129  0.0161  0.0063  0.0119  0.0194  0.0140   \n",
       "97  0.2231  ...  0.0362  0.0210  0.0154  0.0180  0.0013  0.0106  0.0127   \n",
       "98  0.0279  ...  0.0191  0.0182  0.0160  0.0290  0.0090  0.0242  0.0224   \n",
       "99  0.3597  ...  0.0089  0.0262  0.0108  0.0138  0.0187  0.0230  0.0057   \n",
       "\n",
       "    0.0090  0.0032  R  \n",
       "0   0.0052  0.0044  R  \n",
       "1   0.0095  0.0078  R  \n",
       "2   0.0040  0.0117  R  \n",
       "3   0.0107  0.0094  R  \n",
       "4   0.0051  0.0062  R  \n",
       "..     ...     ... ..  \n",
       "95  0.0089  0.0085  R  \n",
       "96  0.0332  0.0439  M  \n",
       "97  0.0178  0.0231  M  \n",
       "98  0.0190  0.0096  M  \n",
       "99  0.0113  0.0131  M  \n",
       "\n",
       "[100 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1528821252801,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "iWOphujj0wal",
    "outputId": "f25c10c0-f029-4554-8767-565b53e0de4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207 entries, 0 to 206\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0.0200  207 non-null    float64\n",
      " 1   0.0371  207 non-null    float64\n",
      " 2   0.0428  207 non-null    float64\n",
      " 3   0.0207  207 non-null    float64\n",
      " 4   0.0954  207 non-null    float64\n",
      " 5   0.0986  207 non-null    float64\n",
      " 6   0.1539  207 non-null    float64\n",
      " 7   0.1601  207 non-null    float64\n",
      " 8   0.3109  207 non-null    float64\n",
      " 9   0.2111  207 non-null    float64\n",
      " 10  0.1609  207 non-null    float64\n",
      " 11  0.1582  207 non-null    float64\n",
      " 12  0.2238  207 non-null    float64\n",
      " 13  0.0645  207 non-null    float64\n",
      " 14  0.0660  207 non-null    float64\n",
      " 15  0.2273  207 non-null    float64\n",
      " 16  0.3100  207 non-null    float64\n",
      " 17  0.2999  207 non-null    float64\n",
      " 18  0.5078  207 non-null    float64\n",
      " 19  0.4797  207 non-null    float64\n",
      " 20  0.5783  207 non-null    float64\n",
      " 21  0.5071  207 non-null    float64\n",
      " 22  0.4328  207 non-null    float64\n",
      " 23  0.5550  207 non-null    float64\n",
      " 24  0.6711  207 non-null    float64\n",
      " 25  0.6415  207 non-null    float64\n",
      " 26  0.7104  207 non-null    float64\n",
      " 27  0.8080  207 non-null    float64\n",
      " 28  0.6791  207 non-null    float64\n",
      " 29  0.3857  207 non-null    float64\n",
      " 30  0.1307  207 non-null    float64\n",
      " 31  0.2604  207 non-null    float64\n",
      " 32  0.5121  207 non-null    float64\n",
      " 33  0.7547  207 non-null    float64\n",
      " 34  0.8537  207 non-null    float64\n",
      " 35  0.8507  207 non-null    float64\n",
      " 36  0.6692  207 non-null    float64\n",
      " 37  0.6097  207 non-null    float64\n",
      " 38  0.4943  207 non-null    float64\n",
      " 39  0.2744  207 non-null    float64\n",
      " 40  0.0510  207 non-null    float64\n",
      " 41  0.2834  207 non-null    float64\n",
      " 42  0.2825  207 non-null    float64\n",
      " 43  0.4256  207 non-null    float64\n",
      " 44  0.2641  207 non-null    float64\n",
      " 45  0.1386  207 non-null    float64\n",
      " 46  0.1051  207 non-null    float64\n",
      " 47  0.1343  207 non-null    float64\n",
      " 48  0.0383  207 non-null    float64\n",
      " 49  0.0324  207 non-null    float64\n",
      " 50  0.0232  207 non-null    float64\n",
      " 51  0.0027  207 non-null    float64\n",
      " 52  0.0065  207 non-null    float64\n",
      " 53  0.0159  207 non-null    float64\n",
      " 54  0.0072  207 non-null    float64\n",
      " 55  0.0167  207 non-null    float64\n",
      " 56  0.0180  207 non-null    float64\n",
      " 57  0.0084  207 non-null    float64\n",
      " 58  0.0090  207 non-null    float64\n",
      " 59  0.0032  207 non-null    float64\n",
      " 60  R       207 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 98.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1528821254114,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "-03RGzFQ0wa3",
    "outputId": "6a0b30b9-2c79-4d54-8a85-2c0397c56d6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029208</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>0.054053</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>0.121591</td>\n",
       "      <td>0.134677</td>\n",
       "      <td>0.177361</td>\n",
       "      <td>0.208245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.006523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.055669</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.061897</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.118311</td>\n",
       "      <td>0.134741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.096750</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.134150</td>\n",
       "      <td>0.153050</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.008550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0.0200      0.0371      0.0428      0.0207      0.0954      0.0986  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.029208    0.038443    0.043837    0.054053    0.075105    0.104599   \n",
       "std      0.023038    0.033040    0.038521    0.046583    0.055669    0.059247   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013300    0.016400    0.018900    0.024450    0.037700    0.066950   \n",
       "50%      0.022800    0.030800    0.034200    0.044100    0.062000    0.092100   \n",
       "75%      0.035800    0.048100    0.058200    0.065700    0.101050    0.134150   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "           0.1539      0.1601      0.3109      0.2111  ...      0.0232  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  ...  207.000000   \n",
       "mean     0.121591    0.134677    0.177361    0.208245  ...    0.016034   \n",
       "std      0.061897    0.085340    0.118311    0.134741  ...    0.012027   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080600    0.080350    0.096750    0.111150  ...    0.008350   \n",
       "50%      0.105600    0.111900    0.152200    0.181000  ...    0.013800   \n",
       "75%      0.153050    0.169800    0.231500    0.269000  ...    0.020700   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "           0.0027      0.0065      0.0159      0.0072      0.0167      0.0180  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.013472    0.010729    0.010917    0.009300    0.008181    0.007771   \n",
       "std      0.009628    0.007071    0.007310    0.007103    0.005719    0.005756   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007350    0.005050    0.005350    0.004100    0.004400    0.003700   \n",
       "50%      0.011500    0.009600    0.009300    0.007500    0.006800    0.005900   \n",
       "75%      0.016750    0.014900    0.014450    0.012100    0.010350    0.010350   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "           0.0084      0.0090      0.0032  \n",
       "count  207.000000  207.000000  207.000000  \n",
       "mean     0.007947    0.007936    0.006523  \n",
       "std      0.006485    0.006196    0.005038  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003650    0.003100  \n",
       "50%      0.005800    0.006300    0.005300  \n",
       "75%      0.010400    0.010350    0.008550  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_H472qQz0wbF"
   },
   "outputs": [],
   "source": [
    "data=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "91vOYbNv0wbS"
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = data[:,0:60].astype(float)\n",
    "Y = data[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1761,
     "status": "ok",
     "timestamp": 1528821259256,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "oV1fOwaq0wbm",
    "outputId": "b5830559-f188-4a5a-f68e-f136c939e0f2"
   },
   "outputs": [],
   "source": [
    "# print(len(X[0]))\n",
    "# print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1528821260439,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "0i8DIUOc0wb1",
    "outputId": "b6c7f95c-9c4c-4bc3-b881-a5e1a396b629"
   },
   "outputs": [],
   "source": [
    "# Y\n",
    "# print(len(Y))\n",
    "# print(len(Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qzo7HLS00wcF"
   },
   "source": [
    "# The output variable is string values. We must convert them into integer values 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wxhfvDgc0wcJ"
   },
   "outputs": [],
   "source": [
    "labelEncode = LabelEncoder()\n",
    "Y =  labelEncode.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1528821262920,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "8PCdkS5q0wcW",
    "outputId": "86eea761-6e96-4bfc-ed6d-af14122b92b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pon5y-m60wch"
   },
   "source": [
    "# Creating a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8bAo4er80wck"
   },
   "outputs": [],
   "source": [
    "# #Initializations define the way to set the initial random weights of Keras layers\n",
    "# from keras import initializers\n",
    "# initial = initializers.random_normal()\n",
    "# def create_baseline():\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(60, input_dim=60, kernel_initializer=initial, activation='relu'))\n",
    "#     model.add(Dense(1, kernel_initializer=initial, activation='sigmoid'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yi5CPSIR0wcz"
   },
   "source": [
    "### Now it is time to evaluate this model using stratified cross validation in the scikit-learn framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58083,
     "status": "ok",
     "timestamp": 1528821322717,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "6JhrMIHE0wdJ",
    "outputId": "9eaf8362-3417-4fcc-8bb9-e21e99233aab"
   },
   "outputs": [],
   "source": [
    "#To use Keras models with scikit-learn, we must use the KerasClassifier wrapper.\n",
    "# estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "# kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(estimator, X, Y, cv=kFolds)\n",
    "# print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJgsjoT60wdj"
   },
   "source": [
    "# Re-Run The Baseline Model With Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 65048,
     "status": "ok",
     "timestamp": 1528821387881,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "MEIML16Q0wdo",
    "outputId": "204a0934-f52b-417d-db44-42c3fcc454b3"
   },
   "outputs": [],
   "source": [
    "# Standardization is important because the data is rescaled such that the mean value for each attribute is 0 and the standard deviation is 1. \n",
    "# evaluate baseline model with standardized dataset\n",
    "# np.random.seed(seed)\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "# pipeline = Pipeline(estimators)\n",
    "# kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(pipeline, X, Y, cv=kFolds)\n",
    "# print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPZOuX-c0wd-"
   },
   "source": [
    "# Tuning Layers and Number of Neurons in The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BI3psMan0weC"
   },
   "source": [
    "### 4.1. Evaluate a Smaller Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71168,
     "status": "ok",
     "timestamp": 1528821459161,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "FtVUrrT70weI",
    "outputId": "2168b635-470d-4911-ce03-7143e38b42c7"
   },
   "outputs": [],
   "source": [
    "# def create_smaller():\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(30, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "# pipeline = Pipeline(estimators)\n",
    "# kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(pipeline, X,Y, cv=kFolds)\n",
    "# print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xeTUfWS0weo"
   },
   "source": [
    "# Step 4.2. Evaluate a Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85414,
     "status": "ok",
     "timestamp": 1528821544682,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "64JiAzls0weu",
    "outputId": "05033c6c-5da8-47af-e354-89ddff53d490"
   },
   "outputs": [],
   "source": [
    "# def create_larger():\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "# pipeline = Pipeline(estimators)\n",
    "# kFolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(pipeline, X, Y, cv=kFolds)\n",
    "# print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjeHvDC30wfJ"
   },
   "source": [
    "# Rewriting the code using the Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17552,
     "status": "ok",
     "timestamp": 1528821562346,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "pfjzF7RS0wfM",
    "outputId": "f7f4d5a1-efbc-4526-c0c5-d868c8f61dc6"
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras import layers\n",
    "# def kerasApiModel():\n",
    "#     # create model\n",
    "#                     inputs = keras.Input(shape=(60,))\n",
    "#                     a = layers.Dense(60, activation='relu')(inputs)\n",
    "#                     a = layers.Dense(10, activation='relu')(a)\n",
    "#                     outputs = layers.Dense(1, activation='sigmoid')(a)\n",
    "#                     model = keras.Model(inputs, outputs)\n",
    "#                      # Compile model\n",
    "#                     model.compile(loss='binary_crossentropy', optimizer='adam',   metrics=['accuracy'])\n",
    "#                     return model\n",
    "\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasClassifier(build_fn=kerasApiModel, epochs=20, batch_size=4, verbose=0)))\n",
    "# pipeline = Pipeline(estimators)\n",
    "# kFolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(pipeline, X, Y, cv=kFolds)\n",
    "# print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlleLLvs0wff"
   },
   "source": [
    "# Rewriting the code by doing Model Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4260,
     "status": "ok",
     "timestamp": 1528821566742,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "IANpKnf30wfh",
    "outputId": "f86db55c-e75d-48f6-a0e1-876db8add873"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# class MyModel(tf.keras.Model):\n",
    "    \n",
    "#         def __init__(self):\n",
    "            \n",
    "#                         super(MyModel, self).__init__()\n",
    "#                         self.dense1 = Dense(60, activation=\"relu\")\n",
    "#                         self.dense2 = Dense(10, activation='relu')\n",
    "#                         self.dense3 = Dense(1, activation='sigmoid')\n",
    "\n",
    "#         def call(self, inputs):\n",
    "\n",
    "#                         x = self.dense1(inputs)\n",
    "#                         x = self.dense2(x)\n",
    "#                         return self.dense3(x)\n",
    "                        \n",
    "                    \n",
    "# model = MyModel()\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam',   metrics=['accuracy'])\n",
    "# model.fit(X,Y, epochs=20, batch_size=4,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3528
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14626,
     "status": "ok",
     "timestamp": 1528822199573,
     "user": {
      "displayName": "Faiz Khan",
      "photoUrl": "//lh3.googleusercontent.com/-tMB38319QFk/AAAAAAAAAAI/AAAAAAAABJs/gA4H_R9Yf3k/s50-c-k-no/photo.jpg",
      "userId": "109729720098117968799"
     },
     "user_tz": -300
    },
    "id": "f8yHXwbU48T5",
    "outputId": "97ab9930-ea97-4dbd-8dec-4db864112bde"
   },
   "outputs": [],
   "source": [
    "# **Build Model from scratch without Scikit Learn**\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "import numpy as np\n",
    "import math\n",
    "scaled_x_train = scaler.fit_transform(X_train)\n",
    "scaled_x_test = scaler.transform(X_test)\n",
    "batch_size = 32\n",
    "from keras import optimizers\n",
    "def final_model():\n",
    "  network = Sequential()\n",
    "  network.add(Dense(60, activation='relu',input_shape=(60,)))\n",
    "  network.add(Dense(30, activation='relu'))\n",
    "  network.add(Dense(1, activation='sigmoid'))\n",
    "  network.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "  return network\n",
    "\n",
    "model1 = final_model()\n",
    "# hist=model1.fit(X_train, Y_train , epochs=40 , batch_size=32, verbose=1, validation_data = (X_test,Y_test))\n",
    "train_error_hist1 = list()\n",
    "test_error_hist1 = list()\n",
    "test_acc_hist1 = list()\n",
    "# batch_size=32\n",
    "itr = 0\n",
    "n_batches = math.ceil(len(scaled_x_train) / batch_size)\n",
    "\n",
    "\n",
    "while itr < 30:\n",
    "    for i in range(n_batches):\n",
    "        X_batch = scaled_x_train[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = Y_train[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        loss = model1.train_on_batch(X_batch, y_batch)\n",
    "        train_error_hist1.append(loss[0])\n",
    "        loss1 = model1.test_on_batch(scaled_x_test, Y_test)\n",
    "        test_error_hist1.append(loss1[0])\n",
    "        test_acc_hist1.append(loss1[1])\n",
    "        \n",
    "        #         print(loss1)\n",
    "        \n",
    "#         print(itr,i,loss)\n",
    "    \n",
    "    itr = itr+1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.65625, 0.65625, 0.6875, 0.71875, 0.6875, 0.6875, 0.71875, 0.75, 0.75, 0.75, 0.78125, 0.78125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.78125, 0.78125, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.78125, 0.75, 0.78125, 0.75, 0.75, 0.78125, 0.75, 0.78125, 0.78125, 0.75, 0.8125, 0.75, 0.8125, 0.78125, 0.78125, 0.8125, 0.78125, 0.8125, 0.78125, 0.78125, 0.8125, 0.78125, 0.8125, 0.78125, 0.78125, 0.8125, 0.78125, 0.8125, 0.78125, 0.78125, 0.8125, 0.8125, 0.78125, 0.78125, 0.78125, 0.78125, 0.8125, 0.78125, 0.78125, 0.78125, 0.78125, 0.8125, 0.78125, 0.78125, 0.8125, 0.78125, 0.8125, 0.78125, 0.8125, 0.8125, 0.78125, 0.8125, 0.78125, 0.8125, 0.8125, 0.78125, 0.8125, 0.78125, 0.8125, 0.8125, 0.78125, 0.8125, 0.78125, 0.8125, 0.8125, 0.78125, 0.8125, 0.78125, 0.8125, 0.8125, 0.78125, 0.8125, 0.78125, 0.8125, 0.8125, 0.8125, 0.78125, 0.8125, 0.8125, 0.78125]\n"
     ]
    }
   ],
   "source": [
    "# model1.batch_size\n",
    "print(test_acc_hist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model1.test_on_batch(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hist['accuracy'],hist['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aQ8Ycj045MOy"
   },
   "outputs": [],
   "source": [
    "# X_train = X\n",
    "# Y_train = Y\n",
    "# X_test = X\n",
    "# Y_test = Y\n",
    "model = final_model()\n",
    "\n",
    "def eval_ratios(sx_train_g, sx_train_b, y_train_g, y_train_b, model):\n",
    "    test_g = model.test_on_batch(sx_train_g,y_train_g)\n",
    "    test_b = model.test_on_batch(sx_train_b,y_train_b)\n",
    "    return 1-test_g[1] + 0.1, 1-test_b[1] + 0.1\n",
    "\n",
    "\n",
    "\n",
    "sx_train_g = scaled_x_train[ Y_train==0 ]\n",
    "sx_train_b = scaled_x_train[ Y_train==1 ]\n",
    "y_train_g = Y_train[Y_train==0]\n",
    "y_train_b = Y_train[Y_train==1]\n",
    "\n",
    "import math\n",
    "# Train\n",
    "train_error_hist = list()\n",
    "test_error_hist = list()\n",
    "test_acc_hist = list()\n",
    "\n",
    "itr = 0\n",
    "n_batches = math.ceil(len(scaled_x_train) / batch_size)\n",
    "\n",
    "\n",
    "ratio_g = 1\n",
    "ratio_b = 1\n",
    "best_model = model\n",
    "best_acc = 0.1\n",
    "best_index = 0\n",
    "\n",
    "# sample_weight = np.random.rand(len(X_train_g[0]))\n",
    "\n",
    "while itr < 30:\n",
    "    \n",
    "    ptr_g = 0\n",
    "    ptr_b = 0\n",
    "\n",
    "    allot_num_g = 1\n",
    "    allot_num_b = 1\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        allot_num_g = ( ratio_g / (ratio_g + ratio_b) )*batch_size\n",
    "        allot_num_g = (int)(allot_num_g)\n",
    "        allot_num_b = batch_size - allot_num_g\n",
    "\n",
    "        X_batch = sx_train_g[ ptr_g: ptr_g+allot_num_g ]\n",
    "        tempp = sx_train_b[ ptr_b: ptr_b+allot_num_b]\n",
    "\n",
    "        X_batch = np.concatenate([X_batch, tempp])\n",
    "        \n",
    "\n",
    "        y_batch = y_train_g[ ptr_g: ptr_g+allot_num_g]\n",
    "        tempp = y_train_b[ ptr_b: ptr_b+allot_num_b]\n",
    "        \n",
    "        y_batch = np.concatenate([y_batch, tempp])\n",
    "        \n",
    "#         print(ptr_g, ptr_b, allot_num_g, allot_num_b)\n",
    "#         print(len(y_batch[y_batch==1]),len(y_batch[y_batch==0])  )\n",
    "\n",
    "#         print(i,\"--------------------------------------------------------------\")\n",
    "#         print(X_batch)\n",
    "#         print(i,\"--------------------------------------------------------------\")\n",
    "#         print(y_batch)\n",
    "#         y_batch = np.concatenate((y_batch, tempp), axis=0 )\n",
    "        \n",
    "#         X_batch = scaled_x_train[i*batch_size:(i+1)*batch_size]\n",
    "#         y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        loss = model.train_on_batch(X_batch, y_batch)\n",
    "#         print(model.layers[0].weights)\n",
    "        train_error_hist.append(loss[0])\n",
    "        \n",
    "        loss1 = model.test_on_batch(scaled_x_test, Y_test)\n",
    "        test_error_hist.append(loss1[0])\n",
    "        test_acc_hist.append(loss1[1])\n",
    "        if loss1[1] > best_acc:\n",
    "            best_model = model\n",
    "            best_index = itr*n_batches+i\n",
    "            \n",
    "        ratio_g, ratio_b = eval_ratios(sx_train_g, sx_train_b, y_train_g, y_train_b, model)\n",
    "#         ratio_g = 1\n",
    "#         ratio_b = 1\n",
    "#         print(ratio_g, ratio_b)\n",
    "        ptr_b+=allot_num_b\n",
    "        ptr_g+=allot_num_g\n",
    "    \n",
    "#     loss1 = model.test_on_batch(scaled_x_test, Y_test)\n",
    "\n",
    "    \n",
    "    itr = itr+1\n",
    "\n",
    "# model.fit(x=scaled_x_train, y=y_train, epochs=iterations, validation_split=validation_split, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.347950279712677, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84375\n",
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "# print(max(test_error_hist))\n",
    "# print(max(train_error_hist))\n",
    "print(max(test_acc_hist))\n",
    "print(max(test_acc_hist1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(max(hist.history['loss']))\n",
    "# print(max(hist.history['val_accuracy']))\n",
    "# print(max(hist.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(test_error_hist)\n",
    "# plt.plot(train_error_hist)\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(hist.history['loss'])\n",
    "# # plt.plot(hist.history['val_loss'])\n",
    "# # plt.plot(test_error_hist)\n",
    "# # plt.plot(train_error_hist)\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper right')\n",
    "# plt.show()\n",
    "# print(max(hist.history['loss']))\n",
    "# # print(max(hist.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_acc_hist)\n",
    "plt.plot(test_acc_hist1)\n",
    "# plt.plot(hist.history['accuracy'])\n",
    "# plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Batches')\n",
    "plt.legend(['Active Sampling', 'Without Active Sampling'], loc='lower right')\n",
    "plt.show()\n",
    "# print(max(test_acc_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "print(max(test_acc_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "print(max(test_acc_hist1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.plot(test_acc_hist)\n",
    "# plt.plot(hist.history['accuracy'])\n",
    "# # plt.plot(hist.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='Weights_folder/Sonar_Weights_AS.h5'\n",
    "model.save_weights(path)\n",
    "path='Weights_folder/Sonar_Weights.h5'\n",
    "model1.save_weights(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def myfunc(x):\n",
    "    if x<0.5:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "yas_pred = model.predict(scaled_x_test)\n",
    "# print(yas_pred)\n",
    "# yas_pred = np.argmax(yas_pred)\n",
    "# print(yas_pred)\n",
    "\n",
    "for i in range(len(yas_pred)):\n",
    "#     print(yas_pred[i])\n",
    "    yas_pred[i] = myfunc(yas_pred[i])\n",
    "# print(yas_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        22\n",
      "           1       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.79      0.75      0.77        32\n",
      "weighted avg       0.81      0.81      0.81        32\n",
      "\n",
      "[[20  2]\n",
      " [ 4  6]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, yas_pred))\n",
    "\n",
    "print(confusion_matrix(Y_test, yas_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        22\n",
      "           1       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.75      0.76      0.75        32\n",
      "weighted avg       0.79      0.78      0.78        32\n",
      "\n",
      "[[18  4]\n",
      " [ 3  7]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(scaled_x_test)\n",
    "# print(yas_pred)\n",
    "# yas_pred = np.argmax(yas_pred)\n",
    "# print(yas_pred)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "#     print(y_pred[i])\n",
    "    y_pred[i] = myfunc(y_pred[i])\n",
    "# print(y_pred)\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Binary Classification.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
